# Homework #4

## Task 1

![alt text](https://github.com/EKorohodov-MS-CS-DSDA/goit-de-hw-04/blob/main/p1_Screenshot.jpg)
Job 0 \- зчитування даних з файла.

Job 1 \- десереалізація даних. Цей крок відбувається через використання функції option("inferSchema", "true") у Spark.read.  

Job 2-4 \- було створено у відповідь на дію “collect” на строчці 27. Кожна з цих Job відповідає трансформації, котра була виконана в момент виклика дії “collect” як ефект “лінивого виконання”.  

Job 2 \- відповідає зчитуванню DataFrame з диску.

Job 3 \- відповідає виклику “repartition”.

Job 4 \- відповідає SQL запиту.

У Job 3-4 бачимо наявність пропущених Stages. Вони є автоматично пропущеними, оскільки дублюють виконання Job-ів, що передували їм.

## Task \#2

![alt text](https://github.com/EKorohodov-MS-CS-DSDA/goit-de-hw-04/blob/main/p2_Screenshot.jpg)
На відміну від попереднього завдання, в SparkUI для цього завдання ми можемо бачити, що окрім Job (2-4), що відповідають тим, що ми бачили в попередньому завданні, додалось ще 3 Job-и (5-7), що були створені у відповідь на дію “collect” на строчці 30\. Вони виконують всі ті самі трансформації, починаючи з читання датафрейма з диску.

## Task \#3

![alt text](https://github.com/EKorohodov-MS-CS-DSDA/goit-de-hw-04/blob/main/p3_Screenshot.jpg)
В третьому завданні ми можемо спостерігати, що кількість Job (5-6) для другого виклику дії “collect” зменшилась на одну. Це є ефектом того, що ми застосували кешування (функція “cache()”), тож читання даного датафрейму відбувається не з диску, а з пам’яті (Memory), і як наслідок, відсутня Job, що відповідає за читання датафрейма з диску.
